---
title: "Prediction of Weight Lifting Activity from Data Provided by Wearable Accelerometers"
author: "wdsteck"
date: '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  pdf_document:
    toc: yes
  html_document:
    keep_md: yes
    theme: united
    toc: yes
---

## Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it.

In this project, the goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants to create a prediction model determining which of the 6 different ways to lift the barbell is being used.

More information is available from [this website](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).

```{r Init, echo=FALSE, results="hide"}
library(caret)
set.seed(33833)
```

## Data

The training data for this project are available here:
```R
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv
```

The test data are available here:
```R
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv
```

## Read in the Data

```{R Introduce Data}

trainFile = "pml-training.csv"
trainURL = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testFile = "pml-testing.csv"
testURL = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

if (!file.exists(trainFile)) {
        download.file(trainURL, trainFile)
}
trainDat <- read.csv(trainFile, stringsAsFactors = TRUE)

if (!file.exists(testFile)) {
        download.file(testURL, testFile)
}
testDat <- read.csv(testFile, stringsAsFactors = TRUE)

```

## Clean Up the Data

We are instructed to use

> data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants

so extract the appropriate features:

```{r Select Columns}
filter = grepl("belt|arm|dumbell|classe", names(trainDat))
trainDat = trainDat[, filter]
testDat = testDat[, filter]
```

If a feature has any `NA` values, then remove the feature. Use the test data to
determine the columns to ensure the model can run on this data.

```{r Remove NA}
filter = colSums(is.na(testDat)) == 0
trainDat = trainDat[, filter]
testDat = testDat[, filter]
```

Ensure that features are not mostly zero nor have zero variability. Any
features mostly zero or with zero variability should be eliminated.
```{r Near Zero}
nearZeroVar(x = trainDat)
```
`NearZeroVar()` returns no covariants that should be removed.

Investigate the correlations between the variables. If there are any
pairs of variables that are highly correlated, then remove one of them.

```{r Clean Correlation}
corMatrix <- cor(trainDat[sapply(trainDat, is.numeric)])
highlyCor = findCorrelation(corMatrix, cutoff = .90)
highlyCor
trainDat <- trainDat[,-highlyCor]
testDat <- testDat[,-highlyCor]
```

## Split Data for Model Creation

Since the training data set is so large (`r length(trainDat$classe)` rows), split
the training set into a training set and a validation set.

```{r Split Training}
inTrain <- createDataPartition(trainDat$classe, p=0.7, list=F)
trainDat.train <- trainDat[inTrain,]
trainDat.valid <- trainDat[-inTrain,]
```

## Model Creation

Now that we have our data ready for model creation, try to create the model
using different generation methods to see which is more accurate.

### Regression Tree Method

```{r Model Rpart}
modFit.rpart <- train(classe ~ ., 
               data=trainDat.train,
               method="rpart")
```

Once the model has been created, determine its accuracy in selecting
the correct activity by predicting each of the validation data samples
and compare them against the true activity.

```{r Accuracy Rpart}
predicted <- predict(modFit.rpart, trainDat.valid)
confusionMatrix(trainDat.valid$classe, predicted)$table
accuracy.rpart <- sum(predicted == trainDat.valid$classe) / length(predicted)
accuracy.rpart
plot(varImp(modFit.rpart))
```

As expected, the accuracy of this model (`r round(accuracy.rpart * 100, 3)`%) is very poor. It is a simple model based on dividing features to isolate answers.

See if others can do better.

### Random Forest Method

```{r Model RF}
modFit.rf <- train(classe ~ ., 
               data=trainDat.train,
               method="rf",
               trControl=trainControl(method="cv", number=4),
               verbose=F)
```

Once the model has been created, determine its accuracy in selecting
the correct activity by predicting each of the validation data samples
and compare them against the true activity.

```{r Accuracy RF}
predicted <- predict(modFit.rf, trainDat.valid)
confusionMatrix(trainDat.valid$classe, predicted)$table
accuracy.rf <- sum(predicted == trainDat.valid$classe) / length(predicted)
accuracy.rf
plot(varImp(modFit.rf))
```

The random forest accuracy is `r round(accuracy.rf * 100, 3)`%, much better,
as expected, than the simple rpart model.

### Boosting Method

```{r Model GBM}
modFit.gbm <- train(classe ~ ., 
               data=trainDat.train,
               method="gbm",
               trControl=trainControl(method="cv", number=4),
               verbose=F)
```

Once the model has been created, determine its accuracy in selecting
the correct activity by predicting each of the validation data samples
and compare them against the true activity.

```{r Accuracy GBM}
predicted <- predict(modFit.gbm, trainDat.valid)
confusionMatrix(trainDat.valid$classe, predicted)$table
accuracy.gbm <- sum(predicted == trainDat.valid$classe) / length(predicted)
accuracy.gbm
plot(varImp(modFit.gbm))
```

The boost model accuracy is `r round(accuracy.gbm * 100, 3)`%, not as good as
the random forest model.

# Conclusion

The accuracy of the random forest model (`r round(accuracy.rf * 100, 3)`%) is
very high. The Random Forest method of model selection has found
a very good prediction model of exercise behavior.

Now, we can predict the outcomes of the test data using the model.

```{r Test Prediction}
predict(modFit.rf, testDat)
```

